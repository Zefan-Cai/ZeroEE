11/05/2023 11:44:21 - INFO - __main__ - ***** Running training *****
11/05/2023 11:44:21 - INFO - __main__ -   Num examples = 151736
11/05/2023 11:44:21 - INFO - __main__ -   Num Epochs = 20
11/05/2023 11:44:21 - INFO - __main__ -   Instantaneous batch size per device = 16
11/05/2023 11:44:21 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/05/2023 11:44:21 - INFO - __main__ -   Gradient Accumulation steps = 1
11/05/2023 11:44:21 - INFO - __main__ -   Total optimization steps = 31620

  0%|                                                                                                                                                              | 1/31620 [00:04<38:21:32,  4.37s/it]11/05/2023 11:44:26 - INFO - __main__ -   Step: 1, LR: 2.1089630931458703e-08, Loss: 5.367490291595459
  0%|                                                                                                                                                              | 2/31620 [00:08<36:23:05,  4.14s/it]11/05/2023 11:44:30 - INFO - __main__ -   Step: 2, LR: 4.2179261862917406e-08, Loss: 5.444327354431152
  0%|                                                                                                                                                              | 3/31620 [00:12<35:48:10,  4.08s/it]11/05/2023 11:44:34 - INFO - __main__ -   Step: 3, LR: 6.32688927943761e-08, Loss: 5.455971717834473
  0%|                                                                                                                                                              | 4/31620 [00:16<35:32:41,  4.05s/it]11/05/2023 11:44:38 - INFO - __main__ -   Step: 4, LR: 8.435852372583481e-08, Loss: 5.431048393249512
11/05/2023 11:44:38 - INFO - __main__ - Start doing evaluation at step: 4

  1%|█                                                                                                                                                                  | 1/150 [00:01<04:26,  1.79s/it]

  2%|███▎                                                                                                                                                               | 3/150 [00:05<04:24,  1.80s/it]

  3%|████▎                                                                                                                                                              | 4/150 [00:07<04:25,  1.82s/it]
torch.Size([32, 252, 32004]) torch.Size([32, 252])

  3%|█████▍                                                                                                                                                             | 5/150 [00:09<04:25,  1.83s/it]

  4%|██████▌                                                                                                                                                            | 6/150 [00:10<04:25,  1.84s/it]

  5%|███████▌                                                                                                                                                           | 7/150 [00:12<04:24,  1.85s/it]

  5%|████████▋                                                                                                                                                          | 8/150 [00:14<04:22,  1.85s/it]

  6%|█████████▊                                                                                                                                                         | 9/150 [00:16<04:21,  1.85s/it]

  7%|██████████▊                                                                                                                                                       | 10/150 [00:18<04:19,  1.85s/it]

  7%|███████████▉                                                                                                                                                      | 11/150 [00:20<04:17,  1.85s/it]

  8%|████████████▉                                                                                                                                                     | 12/150 [00:22<04:16,  1.86s/it]

  9%|██████████████                                                                                                                                                    | 13/150 [00:23<04:14,  1.86s/it]

  9%|███████████████                                                                                                                                                   | 14/150 [00:25<04:12,  1.86s/it]
torch.Size([32, 249, 32004]) torch.Size([32, 249])

 10%|████████████████▏                                                                                                                                                 | 15/150 [00:27<04:10,  1.86s/it]

 11%|██████████████████▎                                                                                                                                               | 17/150 [00:31<04:07,  1.86s/it]

 12%|███████████████████▍                                                                                                                                              | 18/150 [00:33<04:05,  1.86s/it]

 13%|████████████████████▌                                                                                                                                             | 19/150 [00:35<04:03,  1.86s/it]

 13%|█████████████████████▌                                                                                                                                            | 20/150 [00:36<04:01,  1.86s/it]

 14%|██████████████████████▋                                                                                                                                           | 21/150 [00:38<03:59,  1.85s/it]

 15%|███████████████████████▊                                                                                                                                          | 22/150 [00:40<03:57,  1.86s/it]

 15%|████████████████████████▊                                                                                                                                         | 23/150 [00:42<03:55,  1.86s/it]

 16%|█████████████████████████▉                                                                                                                                        | 24/150 [00:44<03:54,  1.86s/it]
Traceback (most recent call last):                                                                                                                                     | 25/150 [00:46<03:52,  1.86s/it]
  File "./open_instruct/open_instruct/finetune_val.py", line 868, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 793, in main
    outputs = model(**eval_batch, use_cache=False, return_dict = True)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1769, in forward
    loss = self.module(*inputs, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 806, in forward
    outputs = self.model(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 693, in forward
    layer_outputs = decoder_layer(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 408, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 306, in forward
    key_states = self.k_proj(hidden_states)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    result = hook(self, args)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 382, in _pre_forward_module_hook
    self.pre_sub_module_forward_function(module)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 494, in pre_sub_module_forward_function
    param_coordinator.fetch_sub_module(sub_module, forward=True)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 295, in fetch_sub_module
    self.__ongoing_fetch_events.popleft().synchronize()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/cuda/streams.py", line 219, in synchronize
    super().synchronize()
KeyboardInterrupt
torch.Size([32, 255, 32004]) torch.Size([32, 255])