11/06/2023 08:35:19 - INFO - __main__ - ***** Running training *****
11/06/2023 08:35:19 - INFO - __main__ -   Num examples = 151736
11/06/2023 08:35:19 - INFO - __main__ -   Num Epochs = 20
11/06/2023 08:35:19 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 08:35:19 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 08:35:19 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 08:35:19 - INFO - __main__ -   Total optimization steps = 31620
  0%|                                                                                                                                                                         | 0/31620 [00:00<?, ?it/s]11/06/2023 08:35:19 - INFO - accelerate.accelerator - Loading states from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
11/06/2023 08:35:19 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
Resumed from checkpoint: /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
[2023-11-06 08:35:19,025] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 08:35:19,037] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 08:35:19,038] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 08:35:19,049] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 08:35:19,059] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-11-06 08:35:23,648] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-11-06 08:35:23,649] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 6 ZeRO state_dicts for rank 0
11/06/2023 08:35:27 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model
11/06/2023 08:35:27 - INFO - accelerate.checkpointing - All model weights loaded successfully
11/06/2023 08:35:27 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
11/06/2023 08:35:27 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
11/06/2023 08:35:27 - INFO - accelerate.checkpointing - All random states loaded successfully
11/06/2023 08:35:27 - INFO - accelerate.accelerator - Loading in 0 custom states
 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:08<00:19, 1140.96it/s]

 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:08<00:19, 1140.96it/s]11/06/2023 08:35:31 - INFO - __main__ -   Step: 9487, LR: 1.4431001684874179e-05, Loss: 0.004177939146757126
11/06/2023 08:35:35 - INFO - __main__ -   Step: 9488, LR: 1.4430349475514975e-05, Loss: 0.000276626436971128
11/06/2023 08:35:36 - INFO - __main__ - Start doing evaluation at step: 9488

 50%|██████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 1/2 [00:08<00:08,  8.68s/it]

11/06/2023 08:35:55 - INFO - __main__ -  [Validation] Step: 9488, Scores: {"accuracy": 0.2373046875, "Positive_Precision": 0.0, "Positive_Recall": 0.0, "Positive_F1": 0.0, "Negative_Precision": 0.3218543046357616, "Negative_Recall": 0.474609375, "Negative_F1": 0.3835832675611681}
11/06/2023 08:35:55 - INFO - __main__ - Start doing evaluation at step: 9488
Traceback (most recent call last):                                                                                                                                               | 0/10 [00:00<?, ?it/s]
  File "./open_instruct/open_instruct/finetune_val.py", line 923, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 873, in main
    outputs = model(**eval_batch, use_cache=False, return_dict = True)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1769, in forward
    loss = self.module(*inputs, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 838, in forward
    loss = loss_fct(shift_logits, shift_labels)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 15.57 GiB (GPU 0; 79.15 GiB total capacity; 59.81 GiB already allocated; 15.37 GiB free; 63.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF