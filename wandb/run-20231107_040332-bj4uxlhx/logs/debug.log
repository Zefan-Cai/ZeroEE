2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Current SDK version is 0.15.8
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Configure stats pid to 4162495
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Loading settings from /home/ponienkung/.config/wandb/settings
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Loading settings from /local1/zefan/ZeroEE/wandb/settings
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'open_instruct/open_instruct/finetune_val.py', 'program': './open_instruct/open_instruct/finetune_val.py'}
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_init.py:_log_setup():507] Logging user logs to /local1/zefan/ZeroEE/wandb/run-20231107_040332-bj4uxlhx/logs/debug.log
2023-11-07 04:03:32,606 INFO    MainThread:4162495 [wandb_init.py:_log_setup():508] Logging internal logs to /local1/zefan/ZeroEE/wandb/run-20231107_040332-bj4uxlhx/logs/debug-internal.log
2023-11-07 04:03:32,607 INFO    MainThread:4162495 [wandb_init.py:init():547] calling init triggers
2023-11-07 04:03:32,607 INFO    MainThread:4162495 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {}
2023-11-07 04:03:32,607 INFO    MainThread:4162495 [wandb_init.py:init():596] starting backend
2023-11-07 04:03:32,607 INFO    MainThread:4162495 [wandb_init.py:init():600] setting up manager
2023-11-07 04:03:32,609 INFO    MainThread:4162495 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-11-07 04:03:32,610 INFO    MainThread:4162495 [wandb_init.py:init():606] backend started and connected
2023-11-07 04:03:32,614 INFO    MainThread:4162495 [wandb_init.py:init():697] updated telemetry
2023-11-07 04:03:32,648 INFO    MainThread:4162495 [wandb_init.py:init():730] communicating run to backend with 60.0 second timeout
2023-11-07 04:03:32,925 INFO    MainThread:4162495 [wandb_run.py:_on_init():2180] communicating current version
2023-11-07 04:03:32,971 INFO    MainThread:4162495 [wandb_run.py:_on_init():2189] got version response upgrade_message: "wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-11-07 04:03:32,971 INFO    MainThread:4162495 [wandb_init.py:init():781] starting run threads in backend
2023-11-07 04:03:34,981 INFO    MainThread:4162495 [wandb_run.py:_console_start():2159] atexit reg
2023-11-07 04:03:34,981 INFO    MainThread:4162495 [wandb_run.py:_redirect():2014] redirect: wrap_raw
2023-11-07 04:03:34,981 INFO    MainThread:4162495 [wandb_run.py:_redirect():2079] Wrapping output streams.
2023-11-07 04:03:34,981 INFO    MainThread:4162495 [wandb_run.py:_redirect():2104] Redirects installed.
2023-11-07 04:03:34,983 INFO    MainThread:4162495 [wandb_init.py:init():822] run started, returning control to user process
2023-11-07 04:03:34,988 INFO    MainThread:4162495 [wandb_run.py:_config_callback():1282] config_cb None None {'dataset_name': None, 'dataset_config_name': None, 'train_file': '/local1/zefan/data/generated_data/train_1definitions_200.json', 'val_file': '/local1/zefan/data/generated_data/val_1definitions.json', 'test_file': '/local1/zefan/data/ace_v2/ACE_valid_GenerationStyle_trigger.json', 'model_name_or_path': '/local1/zefan/output/Llama-2-7b-geneva-20-96-2000/epoch_29', 'config_name': None, 'use_lora': False, 'lora_rank': 64, 'lora_alpha': 16, 'lora_dropout': 0.1, 'save_merged_lora_model': False, 'use_flash_attn': True, 'tokenizer_name': '/local1/zefan/models/Llama-2-7b-hf/', 'use_slow_tokenizer': True, 'max_seq_length': 256, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 256, 'learning_rate': 2e-05, 'weight_decay': 0.0, 'num_train_epochs': 20, 'max_train_steps': 31620, 'gradient_accumulation_steps': 1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.03, 'output_dir': '/local1/zefan/output/Llama2_Geneva_20_96_2000_GenData200/', 'seed': None, 'preprocessing_num_workers': 16, 'overwrite_cache': False, 'checkpointing_steps': 'epoch', 'eval_steps': 4, 'logging_steps': 1, 'resume_from_checkpoint': None, 'with_tracking': True, 'report_to': 'wandb', 'report_name': 'Llama2_Geneva_20_96_2000_GenData200/', 'report_tags': ['CtrlGen'], 'low_cpu_mem_usage': False}
