Resumed from checkpoint: /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
[2023-11-06 08:34:04,967] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 08:34:04,979] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 08:34:04,980] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 08:34:04,991] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 08:34:05,001] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
11/06/2023 08:34:04 - INFO - __main__ - ***** Running training *****
11/06/2023 08:34:04 - INFO - __main__ -   Num examples = 151736
11/06/2023 08:34:04 - INFO - __main__ -   Num Epochs = 20
11/06/2023 08:34:04 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 08:34:04 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 08:34:04 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 08:34:04 - INFO - __main__ -   Total optimization steps = 31620
  0%|                                                                                                                                                                         | 0/31620 [00:00<?, ?it/s]11/06/2023 08:34:04 - INFO - accelerate.accelerator - Loading states from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
11/06/2023 08:34:04 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
[2023-11-06 08:34:09,041] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-11-06 08:34:09,041] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 6 ZeRO state_dicts for rank 0
[2023-11-06 08:34:12,307] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 6 zero partition checkpoints for rank 0
11/06/2023 08:34:12 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model
11/06/2023 08:34:12 - INFO - accelerate.checkpointing - All model weights loaded successfully
11/06/2023 08:34:12 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
11/06/2023 08:34:12 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
11/06/2023 08:34:12 - INFO - accelerate.checkpointing - All random states loaded successfully
11/06/2023 08:34:12 - INFO - accelerate.accelerator - Loading in 0 custom states

 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:07<00:17, 1236.74it/s]11/06/2023 08:34:17 - INFO - __main__ -   Step: 9487, LR: 1.4431001684874179e-05, Loss: 0.004177939146757126
11/06/2023 08:34:21 - INFO - __main__ -   Step: 9488, LR: 1.4430349475514975e-05, Loss: 0.000276626436971128
11/06/2023 08:34:21 - INFO - __main__ - Start doing evaluation at step: 9488



 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 3/4 [00:14<00:04,  4.69s/it]
11/06/2023 08:34:39 - INFO - __main__ -  [Validation] Step: 9488, Scores: {"accuracy": 0.1181640625, "Positive_Precision": 0.0, "Positive_Recall": 0.0, "Positive_F1": 0.0, "Negative_Precision": 0.19298245614035087, "Negative_Recall": 0.2335907335907336, "Negative_F1": 0.211353711790393}
11/06/2023 08:34:39 - INFO - __main__ - Start doing evaluation at step: 9488
Traceback (most recent call last):                                                                                                                                               | 0/20 [00:00<?, ?it/s]
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/tqdm/std.py", line 1197, in __iter__
    self.close()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/tqdm/std.py", line 1291, in close
    fp_write('')
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/tqdm/std.py", line 1288, in fp_write
    self.fp.write(str(s))
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/tqdm/utils.py", line 195, in inner
    return func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/lib/redirect.py", line 643, in write
    cb(data)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 2089, in <lambda>
    lambda data: self._console_raw_callback("stderr", data),
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 341, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 1423, in _console_raw_callback
    self._backend.interface.publish_output_raw(name, data)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 725, in publish_output_raw
    self._publish_output_raw(o)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 79, in _publish_output_raw
    self._publish(rec)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 126, in _sendall_with_error_handle
    total_data = len(data)
KeyboardInterrupt:
Traceback (most recent call last):
  File "./open_instruct/open_instruct/finetune_val.py", line 923, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 878, in main
    scores_metric.add_batch(predictions=batch_predict, references=test_gt)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/datasets/metric.py", line 496, in add_batch
    self._init_writer()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/datasets/metric.py", line 578, in _init_writer
    cache_file_name, filelock = self._create_cache_file()  # get ready
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/datasets/metric.py", line 272, in _create_cache_file
    filelock.acquire(timeout=timeout)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/datasets/utils/filelock.py", line 282, in acquire
    time.sleep(poll_intervall)
KeyboardInterrupt