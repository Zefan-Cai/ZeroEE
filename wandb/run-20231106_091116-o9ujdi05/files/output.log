11/06/2023 09:11:19 - INFO - __main__ - ***** Running training *****
11/06/2023 09:11:19 - INFO - __main__ -   Num examples = 363935
11/06/2023 09:11:19 - INFO - __main__ -   Num Epochs = 20
11/06/2023 09:11:19 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 09:11:19 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 09:11:19 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 09:11:19 - INFO - __main__ -   Total optimization steps = 75820
  0%|                                                                                                                                                              | 1/75820 [00:04<92:49:46,  4.41s/it]11/06/2023 09:11:23 - INFO - __main__ -   Step: 1, LR: 8.793141349747198e-09, Loss: 5.385743141174316
11/06/2023 09:11:23 - INFO - __main__ - args.eval_steps is None. Set to do eval after each epoch, which is 3791
  0%|                                                                                                                                                              | 2/75820 [00:08<87:37:10,  4.16s/it]11/06/2023 09:11:27 - INFO - __main__ -   Step: 2, LR: 1.7586282699494396e-08, Loss: 5.310622692108154
  0%|                                                                                                                                                              | 3/75820 [00:12<85:54:39,  4.08s/it]11/06/2023 09:11:31 - INFO - __main__ -   Step: 3, LR: 2.6379424049241596e-08, Loss: 5.338367462158203
  0%|                                                                                                                                                              | 4/75820 [00:16<85:16:44,  4.05s/it]11/06/2023 09:11:35 - INFO - __main__ -   Step: 4, LR: 3.517256539898879e-08, Loss: 5.384025573730469
  0%|                                                                                                                                                              | 5/75820 [00:20<84:48:21,  4.03s/it]11/06/2023 09:11:39 - INFO - __main__ -   Step: 5, LR: 4.396570674873599e-08, Loss: 5.482884883880615
  0%|                                                                                                                                                              | 6/75820 [00:24<84:33:06,  4.01s/it]11/06/2023 09:11:43 - INFO - __main__ -   Step: 6, LR: 5.275884809848319e-08, Loss: 5.3233537673950195
  0%|                                                                                                                                                              | 7/75820 [00:28<84:25:01,  4.01s/it]11/06/2023 09:11:47 - INFO - __main__ -   Step: 7, LR: 6.155198944823039e-08, Loss: 5.3744964599609375
  0%|                                                                                                                                                              | 8/75820 [00:32<84:14:32,  4.00s/it]11/06/2023 09:11:51 - INFO - __main__ -   Step: 8, LR: 7.034513079797758e-08, Loss: 5.434349060058594
  0%|                                                                                                                                                              | 9/75820 [00:36<84:09:47,  4.00s/it]11/06/2023 09:11:55 - INFO - __main__ -   Step: 9, LR: 7.913827214772478e-08, Loss: 5.299910545349121
  0%|                                                                                                                                                             | 10/75820 [00:40<84:07:07,  3.99s/it]11/06/2023 09:11:59 - INFO - __main__ -   Step: 10, LR: 8.793141349747198e-08, Loss: 5.365216255187988
  0%|                                                                                                                                                             | 11/75820 [00:44<84:04:19,  3.99s/it]11/06/2023 09:12:03 - INFO - __main__ -   Step: 11, LR: 9.672455484721917e-08, Loss: 5.428523063659668
  0%|                                                                                                                                                             | 12/75820 [00:48<83:59:21,  3.99s/it]11/06/2023 09:12:07 - INFO - __main__ -   Step: 12, LR: 1.0551769619696638e-07, Loss: 5.365102291107178
  0%|                                                                                                                                                             | 13/75820 [00:52<84:00:52,  3.99s/it]11/06/2023 09:12:11 - INFO - __main__ -   Step: 13, LR: 1.1431083754671358e-07, Loss: 5.267375469207764
  0%|                                                                                                                                                             | 14/75820 [00:56<84:02:07,  3.99s/it]11/06/2023 09:12:15 - INFO - __main__ -   Step: 14, LR: 1.2310397889646078e-07, Loss: 5.352841854095459
  0%|                                                                                                                                                             | 15/75820 [01:00<84:34:38,  4.02s/it]11/06/2023 09:12:19 - INFO - __main__ -   Step: 15, LR: 1.3189712024620796e-07, Loss: 5.290740013122559
  0%|                                                                                                                                                             | 16/75820 [01:04<84:24:39,  4.01s/it]11/06/2023 09:12:23 - INFO - __main__ -   Step: 16, LR: 1.4069026159595517e-07, Loss: 5.210919380187988
  0%|                                                                                                                                                             | 17/75820 [01:08<84:16:27,  4.00s/it]11/06/2023 09:12:27 - INFO - __main__ -   Step: 17, LR: 1.4948340294570238e-07, Loss: 5.145237445831299
  0%|                                                                                                                                                             | 18/75820 [01:12<84:12:16,  4.00s/it]11/06/2023 09:12:31 - INFO - __main__ -   Step: 18, LR: 1.5827654429544956e-07, Loss: 5.145843505859375
