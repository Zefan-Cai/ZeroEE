11/06/2023 03:24:56 - INFO - __main__ - ***** Running training *****
11/06/2023 03:24:56 - INFO - __main__ -   Num examples = 151736
11/06/2023 03:24:56 - INFO - __main__ -   Num Epochs = 20
11/06/2023 03:24:56 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 03:24:56 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 03:24:56 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 03:24:56 - INFO - __main__ -   Total optimization steps = 31620
  0%|                                                                                                                                                                         | 0/31620 [00:00<?, ?it/s]11/06/2023 03:24:56 - INFO - accelerate.accelerator - Loading states from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
11/06/2023 03:24:56 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
Resumed from checkpoint: /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
[2023-11-06 03:24:56,466] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 03:24:56,479] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 03:24:56,479] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 03:24:56,490] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 03:24:56,500] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-11-06 03:25:01,004] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-11-06 03:25:01,004] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 6 ZeRO state_dicts for rank 0
[2023-11-06 03:25:03,840] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 6 zero partition checkpoints for rank 0
11/06/2023 03:25:04 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model
11/06/2023 03:25:04 - INFO - accelerate.checkpointing - All model weights loaded successfully
11/06/2023 03:25:04 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
11/06/2023 03:25:04 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
11/06/2023 03:25:04 - INFO - accelerate.checkpointing - All random states loaded successfully
11/06/2023 03:25:04 - INFO - accelerate.accelerator - Loading in 0 custom states

 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:07<00:18, 1194.49it/s]11/06/2023 03:25:08 - INFO - __main__ -   Step: 9487, LR: 1.4431001684874179e-05, Loss: 0.004177939146757126
11/06/2023 03:25:12 - INFO - __main__ -   Step: 9488, LR: 1.4430349475514975e-05, Loss: 0.000276626436971128
11/06/2023 03:25:13 - INFO - __main__ - Start doing evaluation at step: 9488

 14%|███████████████████████▌                                                                                                                                             | 1/7 [00:02<00:15,  2.56s/it]

 29%|███████████████████████████████████████████████▏                                                                                                                     | 2/7 [00:05<00:12,  2.52s/it]
torch.Size([128, 183, 32004]) torch.Size([128, 183])


 57%|██████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 4/7 [00:09<00:07,  2.41s/it]

 71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 5/7 [00:12<00:04,  2.42s/it]

 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 6/7 [00:14<00:02,  2.33s/it]
/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
torch.Size([128, 149, 32004]) torch.Size([128, 149])
Pred: 29889, GT: 16387
Pred: ., GT: realized
Pred: 29889, GT: 10943
Pred: ., GT: discovered
Pred: 29889, GT: 10548
Pred: ., GT: noticed
Pred: 29889, GT: 16387
Pred: ., GT: realized
Pred: 29889, GT: 443
Pred: ., GT: un
Pred: 29889, GT: 10943
Pred: ., GT: discovered
Pred: 29889, GT: 14831
Pred: ., GT: recognized
Pred: 29889, GT: 16387
Pred: ., GT: realized
Pred: 29889, GT: 10943
Pred: ., GT: discovered
Pred: 29889, GT: 10548
Pred: ., GT: noticed
Pred: 29889, GT: 14831
Pred: ., GT: recognized
Pred: 29889, GT: 17515
Pred: ., GT: gained
Pred: 29889, GT: 11098
Pred: ., GT: understood
Pred: 29889, GT: 16692
Pred: ., GT: acquired
Pred: 29889, GT: 16387
Pred: ., GT: realized
Pred: 29889, GT: 22229
Pred: ., GT: gathered
Pred: 29889, GT: 10972
Pred: ., GT: learned
Pred: 29889, GT: 10943
Pred: ., GT: discovered
Pred: 29889, GT: 5835
Pred: ., GT: master
Pred: 29889, GT: 8906
Pred: ., GT: developed
Pred: 29889, GT: 9177
Pred: ., GT: warning
Pred: 29889, GT: 9177
Pred: ., GT: warning
Pred: 29889, GT: 29383
Pred: ., GT: warn
Pred: 29889, GT: 1871
Pred: ., GT: inform
Pred: 29889, GT: 9177
Pred: ., GT: warning
Pred: 29889, GT: 9177
Pred: ., GT: warning
Pred: 29889, GT: 17386
Pred: ., GT: recall
Pred: 29889, GT: 5353
Pred: ., GT: discuss
Pred: 29889, GT: 7182
Pred: ., GT: signal
Pred: 29889, GT: 9177
Pred: ., GT: warning
Pred: 29889, GT: 2906
Pred: ., GT: dev
Pred: 29889, GT: 6635
Pred: ., GT: cat
Pred: 29889, GT: 25305
Pred: ., GT: trag
Pred: 29889, GT: 16403
Pred: ., GT: terrible
Pred: 1, GT: 2906
Pred: <s>, GT: dev
Pred: 29889, GT: 766
Pred: ., GT: dis
Pred: 29889, GT: 9358
Pred: ., GT: ep
Pred: 29889, GT: 6635
Pred: ., GT: cat
Pred: 29889, GT: 2906
Pred: ., GT: dev
Pred: 29889, GT: 1020
Pred: ., GT: tra
Pred: 29889, GT: 7180
Pred: ., GT: placed
Pred: 29889, GT: 1476
Pred: ., GT: found
Pred: 29889, GT: 639
Pred: ., GT: per
Pred: 29889, GT: 14089
Pred: ., GT: park
Pred: 29889, GT: 8833
Pred: ., GT: displayed
Pred: 29889, GT: 5685
Pred: ., GT: flo
Pred: 29889, GT: 4240
Pred: ., GT: built
Pred: 29889, GT: 7180
Pred: ., GT: placed
Pred: 29889, GT: 10943
Pred: ., GT: discovered
Pred: 29889, GT: 14737
Pred: ., GT: ere
Pred: 29889, GT: 21050
Pred: ., GT: arranged
Pred: 29889, GT: 2602
Pred: ., GT: position
Pred: 29889, GT: 2602
Pred: ., GT: position
Pred: 29889, GT: 4629
Pred: ., GT: selected
Pred: 29889, GT: 21050
Pred: ., GT: arranged
Pred: 29889, GT: 2602
Pred: ., GT: position
Pred: 29889, GT: 7180
Pred: ., GT: placed
Pred: 29889, GT: 8833
Pred: ., GT: displayed
Pred: 29889, GT: 4629
Pred: ., GT: selected
Pred: 29889, GT: 10624
Pred: ., GT: directed
/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
11/06/2023 03:25:30 - INFO - __main__ -  [Validation] Step: 9488, Scores: {"val_Accuracy": 0.0, "val_Positive_Precision": 0.0, "val_Positive_Recall": 0.0, "val_Positive_F1": 0.0, "val_Negative_Precision": 0.0, "val_Negative_Recall": 0.0, "val_Negative_F1": 0.0}
11/06/2023 03:25:30 - INFO - __main__ - Start doing evaluation at step: 9488



Traceback (most recent call last):                                                                                                                                       | 5/38 [00:16<01:47,  3.26s/it]
  File "./open_instruct/open_instruct/finetune_val.py", line 894, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 846, in main
    outputs = model(**eval_batch, use_cache=False, return_dict = True)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1769, in forward
    loss = self.module(*inputs, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 806, in forward
    outputs = self.model(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 693, in forward
    layer_outputs = decoder_layer(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 408, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 306, in forward
    key_states = self.k_proj(hidden_states)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    result = hook(self, args)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 382, in _pre_forward_module_hook
    self.pre_sub_module_forward_function(module)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 494, in pre_sub_module_forward_function
    param_coordinator.fetch_sub_module(sub_module, forward=True)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 295, in fetch_sub_module
    self.__ongoing_fetch_events.popleft().synchronize()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/cuda/streams.py", line 219, in synchronize
    super().synchronize()
KeyboardInterrupt