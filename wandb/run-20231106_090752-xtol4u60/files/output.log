11/06/2023 09:07:54 - INFO - __main__ - ***** Running training *****
11/06/2023 09:07:54 - INFO - __main__ -   Num examples = 363935
11/06/2023 09:07:54 - INFO - __main__ -   Num Epochs = 20
11/06/2023 09:07:54 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 09:07:54 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 09:07:54 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 09:07:54 - INFO - __main__ -   Total optimization steps = 75820
  0%|                                                                                                                                                              | 1/75820 [00:04<92:59:10,  4.42s/it]11/06/2023 09:07:59 - INFO - __main__ -   Step: 1, LR: 8.793141349747198e-09, Loss: 5.37799596786499
11/06/2023 09:07:59 - INFO - __main__ - args.eval_steps is None. Set to do eval after each epoch, which is 3791
  0%|                                                                                                                                                              | 2/75820 [00:08<87:46:32,  4.17s/it]11/06/2023 09:08:03 - INFO - __main__ -   Step: 2, LR: 1.7586282699494396e-08, Loss: 5.295337677001953
  0%|                                                                                                                                                              | 3/75820 [00:12<86:05:28,  4.09s/it]11/06/2023 09:08:07 - INFO - __main__ -   Step: 3, LR: 2.6379424049241596e-08, Loss: 5.340816497802734
  0%|                                                                                                                                                              | 4/75820 [00:16<85:20:44,  4.05s/it]11/06/2023 09:08:11 - INFO - __main__ -   Step: 4, LR: 3.517256539898879e-08, Loss: 5.376789093017578
  0%|                                                                                                                                                              | 5/75820 [00:20<84:51:47,  4.03s/it]11/06/2023 09:08:15 - INFO - __main__ -   Step: 5, LR: 4.396570674873599e-08, Loss: 5.471693992614746
  0%|                                                                                                                                                              | 6/75820 [00:24<84:34:51,  4.02s/it]11/06/2023 09:08:19 - INFO - __main__ -   Step: 6, LR: 5.275884809848319e-08, Loss: 5.294239044189453
  0%|                                                                                                                                                              | 7/75820 [00:28<84:25:03,  4.01s/it]11/06/2023 09:08:23 - INFO - __main__ -   Step: 7, LR: 6.155198944823039e-08, Loss: 5.363661766052246
  0%|                                                                                                                                                              | 8/75820 [00:32<84:15:08,  4.00s/it]11/06/2023 09:08:27 - INFO - __main__ -   Step: 8, LR: 7.034513079797758e-08, Loss: 5.419002532958984
  0%|                                                                                                                                                              | 9/75820 [00:36<84:10:43,  4.00s/it]11/06/2023 09:08:31 - INFO - __main__ -   Step: 9, LR: 7.913827214772478e-08, Loss: 5.306272029876709
  0%|                                                                                                                                                             | 10/75820 [00:40<84:08:37,  4.00s/it]11/06/2023 09:08:35 - INFO - __main__ -   Step: 10, LR: 8.793141349747198e-08, Loss: 5.367648601531982
  0%|                                                                                                                                                             | 11/75820 [00:44<84:08:29,  4.00s/it]11/06/2023 09:08:39 - INFO - __main__ -   Step: 11, LR: 9.672455484721917e-08, Loss: 5.436319351196289
  0%|                                                                                                                                                             | 12/75820 [00:48<84:01:28,  3.99s/it]11/06/2023 09:08:43 - INFO - __main__ -   Step: 12, LR: 1.0551769619696638e-07, Loss: 5.3185248374938965
  0%|                                                                                                                                                             | 13/75820 [00:52<84:05:01,  3.99s/it]11/06/2023 09:08:47 - INFO - __main__ -   Step: 13, LR: 1.1431083754671358e-07, Loss: 5.2996110916137695
  0%|                                                                                                                                                             | 14/75820 [00:56<84:01:47,  3.99s/it]11/06/2023 09:08:51 - INFO - __main__ -   Step: 14, LR: 1.2310397889646078e-07, Loss: 5.355672836303711
  0%|                                                                                                                                                             | 15/75820 [01:00<84:35:42,  4.02s/it]11/06/2023 09:08:55 - INFO - __main__ -   Step: 15, LR: 1.3189712024620796e-07, Loss: 5.280614852905273
  0%|                                                                                                                                                             | 16/75820 [01:04<84:24:06,  4.01s/it]11/06/2023 09:08:59 - INFO - __main__ -   Step: 16, LR: 1.4069026159595517e-07, Loss: 5.169761657714844
  0%|                                                                                                                                                             | 17/75820 [01:08<84:22:52,  4.01s/it]11/06/2023 09:09:03 - INFO - __main__ -   Step: 17, LR: 1.4948340294570238e-07, Loss: 5.120848655700684
  0%|                                                                                                                                                             | 18/75820 [01:12<84:18:25,  4.00s/it]11/06/2023 09:09:07 - INFO - __main__ -   Step: 18, LR: 1.5827654429544956e-07, Loss: 5.121445655822754
  0%|                                                                                                                                                             | 19/75820 [01:16<84:12:24,  4.00s/it]11/06/2023 09:09:11 - INFO - __main__ -   Step: 19, LR: 1.6706968564519674e-07, Loss: 4.9192094802856445
  0%|                                                                                                                                                             | 20/75820 [01:20<84:09:38,  4.00s/it]11/06/2023 09:09:15 - INFO - __main__ -   Step: 20, LR: 1.7586282699494395e-07, Loss: 5.104446887969971
  0%|                                                                                                                                                             | 21/75820 [01:24<84:09:24,  4.00s/it]11/06/2023 09:09:19 - INFO - __main__ -   Step: 21, LR: 1.8465596834469114e-07, Loss: 5.019371509552002
Traceback (most recent call last):
  File "./open_instruct/open_instruct/finetune_val.py", line 923, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 786, in main
    accelerator.backward(loss)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/accelerate/accelerator.py", line 1847, in backward
    self.deepspeed_engine_wrapped.backward(loss, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 176, in backward
    self.engine.step()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2087, in step
    self._take_model_step(lr_kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1994, in _take_model_step
    self.optimizer.step()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/stage3.py", line 1891, in step
    self._post_step(timer_names)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/stage3.py", line 1817, in _post_step
    self.persistent_parameters[0].all_gather(self.persistent_parameters)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 983, in all_gather
    return self._all_gather(param_list, async_op=async_op, hierarchy=hierarchy)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1283, in _all_gather
    ret_value = self._allgather_params_coalesced(all_gather_list, hierarchy)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1591, in _allgather_params_coalesced
    get_accelerator().synchronize()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/accelerator/cuda_accelerator.py", line 50, in synchronize
    return torch.cuda.synchronize(device_index)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/cuda/__init__.py", line 688, in synchronize
    return torch._C._cuda_synchronize()
KeyboardInterrupt