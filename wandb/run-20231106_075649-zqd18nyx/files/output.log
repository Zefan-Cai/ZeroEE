11/06/2023 07:56:51 - INFO - __main__ - ***** Running training *****
11/06/2023 07:56:51 - INFO - __main__ -   Num examples = 151736
11/06/2023 07:56:51 - INFO - __main__ -   Num Epochs = 20
11/06/2023 07:56:51 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 07:56:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 07:56:51 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 07:56:51 - INFO - __main__ -   Total optimization steps = 31620
  0%|                                                                                                                                                                         | 0/31620 [00:00<?, ?it/s]11/06/2023 07:56:51 - INFO - accelerate.accelerator - Loading states from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
11/06/2023 07:56:51 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
Resumed from checkpoint: /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
[2023-11-06 07:56:51,826] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 07:56:51,839] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 07:56:51,840] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 07:56:51,850] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 07:56:51,861] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-11-06 07:56:56,502] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-11-06 07:56:56,503] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 6 ZeRO state_dicts for rank 0
[2023-11-06 07:56:59,578] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 6 zero partition checkpoints for rank 0
11/06/2023 07:57:00 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model
11/06/2023 07:57:00 - INFO - accelerate.checkpointing - All model weights loaded successfully
11/06/2023 07:57:00 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
11/06/2023 07:57:00 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
11/06/2023 07:57:00 - INFO - accelerate.checkpointing - All random states loaded successfully
11/06/2023 07:57:00 - INFO - accelerate.accelerator - Loading in 0 custom states

 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:08<00:19, 1144.50it/s]11/06/2023 07:57:04 - INFO - __main__ -   Step: 9487, LR: 1.4431001684874179e-05, Loss: 0.004177939146757126
11/06/2023 07:57:08 - INFO - __main__ -   Step: 9488, LR: 1.4430349475514975e-05, Loss: 0.000276626436971128
11/06/2023 07:57:09 - INFO - __main__ - Start doing evaluation at step: 9488
  0%|                                                                                                                                                                             | 0/4 [00:00<?, ?it/s]
Traceback (most recent call last):                                                                                                                                                | 0/4 [00:00<?, ?it/s]
  File "./open_instruct/open_instruct/finetune_val.py", line 911, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 832, in main
    outputs = model(**eval_batch, use_cache=False, return_dict = True)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1769, in forward
    loss = self.module(*inputs, **kwargs)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
TypeError: forward() got an unexpected keyword argument 'trigger'
debug eval_batch {'trigger': tensor([[    1, 16387],
        [    1, 10943],
        [    1, 10548],
        [    1, 16387],
        [    1,   443],
        [    1, 10943],
        [    1, 14831],
        [    1, 16387],
        [    1, 10943],
        [    1, 10548],
        [    1, 14831],
        [    1, 17515],
        [    1, 11098],
        [    1, 16692],
        [    1, 16387],
        [    1, 22229],
        [    1, 10972],
        [    1, 10943],
        [    1,  5835],
        [    1,  8906],
        [    1,  9177],
        [    1,  9177],
        [    1, 29383],
        [    1,  1871],
        [    1,  9177],
        [    1,  9177],
        [    1, 17386],
        [    1,  5353],
        [    1,  7182],
        [    1,  9177],
        [    1,  2906],
        [    1,  6635],
        [    1, 25305],
        [    1, 16403],
        [    1,  2906],
        [    1,   766],
        [    1,  9358],
        [    1,  6635],
        [    1,  2906],
        [    1,  1020],
        [    1,  7180],
        [    1,  1476],
        [    1,   639],
        [    1, 14089],
        [    1,  8833],
        [    1,  5685],
        [    1,  4240],
        [    1,  7180],
        [    1, 10943],
        [    1, 14737],
        [    1, 21050],
        [    1,  2602],
        [    1,  2602],
        [    1,  4629],
        [    1, 21050],
        [    1,  2602],
        [    1,  7180],
        [    1,  8833],
        [    1,  4629],
        [    1, 10624],
        [    1,  1476],
        [    1, 17141],
        [    1,  2175],
        [    1,  7180],
        [    1,  9698],
        [    1,  6153],
        [    1,  6087],
        [    1,  7500],
        [    1,   620],
        [    1, 21050],
        [    1,  5330],
        [    1, 19799],
        [    1, 16267],
        [    1, 14511],
        [    1,  5331],
        [    1,   731],
        [    1,  5330],
        [    1, 19799],
        [    1, 14511],
        [    1, 16267],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 12853],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1,  1395],
        [    1, 18517],
        [    1,  5768],
        [    1, 16671],
        [    1,  6493],
        [    1,   772],
        [    1,  5146],
        [    1,  8459],
        [    1,  2714],
        [    1, 16671],
        [    1,   772],
        [    1, 18014],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 18517],
        [    1, 26834],
        [    1, 10018],
        [    1,   885],
        [    1,  9132],
        [    1,  7625],
        [    1,  8794],
        [    1, 13877],
        [    1, 10018],
        [    1,  1304],
        [    1,  4520],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1, 11977],
        [    1,  6974],
        [    1,  6974],
        [    1, 18331],
        [    1, 18331],
        [    1, 18517],
        [    1, 18517],
        [    1, 18331],
        [    1, 18331],
        [    1, 18517],
        [    1, 18331],
        [    1, 20115],
        [    1, 14523],
        [    1, 27214],
        [    1,  4520],
        [    1,  5839],
        [    1, 28289],
        [    1,  7751],
        [    1, 11817],
        [    1,  2143],
        [    1, 10804],
        [    1, 20115],
        [    1, 23110],
        [    1,  3234],
        [    1,  9659],
        [    1, 13271],
        [    1,  6909],
        [    1,  9528],
        [    1, 28289],
        [    1,  1361],
        [    1,  2894],
        [    1, 20115],
        [    1,  8676],
        [    1,  4944],
        [    1, 13916],
        [    1,  9259],
        [    1, 20115],
        [    1, 29692],
        [    1, 21467],
        [    1,  1754],
        [    1,  8676],
        [    1, 20115],
        [    1, 28289],
        [    1, 29692],
        [    1, 13916],
        [    1,  3271],
        [    1,  1021],
        [    1, 18440],
        [    1, 20115],
        [    1,  8608],
        [    1, 28289],
        [    1,  5239],
        [    1,  1016],
        [    1,  4502],
        [    1,  8794],
        [    1,   281],
        [    1, 15074],
        [    1, 16896],
        [    1,  5239],
        [    1, 20848],
        [    1,  2665],
        [    1, 28289],
        [    1,  6782],
        [    1, 28289],
        [    1,  6782],
        [    1,  4918],
        [    1,  6782],
        [    1, 28289],
        [    1,  6782],
        [    1,  6782],
        [    1, 28705],
        [    1,  9132],
        [    1, 10824],
        [    1,  2553],
        [    1, 29537],
        [    1, 15648],
        [    1,  9132],
        [    1, 29537],
        [    1,  8575],
        [    1, 22229],
        [    1,  3512],
        [    1, 19098],
        [    1, 24370],
        [    1, 19098],
        [    1,  4934],
        [    1,  4934],
        [    1, 19098],
        [    1,  4934],
        [    1, 21130],
        [    1,  7952],
        [    1,  4772],
        [    1,  7952],
        [    1,   269],
        [    1,  1886],
        [    1, 25349],
        [    1, 27661],
        [    1, 14993],
        [    1,   491],
        [    1, 11084],
        [    1,  5557],
        [    1,  6068],
        [    1, 28305],
        [    1, 25212],
        [    1, 11084],
        [    1,  6068],
        [    1,  5557],
        [    1,  6068],
        [    1, 11084],
        [    1,  8581],
        [    1, 11826],
        [    1, 28482],
        [    1,  2825],
        [    1,  8581],
        [    1,  8608],
        [    1,  8581],
        [    1, 20601],
        [    1, 18342],
        [    1, 20704],
        [    1,   285],
        [    1, 19174],
        [    1,  2318],
        [    1,   902],
        [    1,  2381],
        [    1,  4870],
        [    1,  3762],
        [    1,  9987],
        [    1,  2318]], device='cuda:0'), 'input_ids': tensor([[    1,   317,  3919,  ..., 32003, 32003, 32003],
        [    1,   317,  3919,  ..., 32003, 32003, 32003],
        [    1,   317,  3919,  ..., 32003, 32003, 32003],
        ...,
        [    1,   317,  3919,  ..., 32003, 32003, 32003],
        [    1,   317,  3919,  ..., 32003, 32003, 32003],
        [    1,   317,  3919,  ..., 32003, 32003, 32003]], device='cuda:0'), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],
        [-100, -100, -100,  ..., -100, -100, -100],
        [-100, -100, -100,  ..., -100, -100, -100],
        ...,
        [-100, -100, -100,  ..., -100, -100, -100],
        [-100, -100, -100,  ..., -100, -100, -100],
        [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}