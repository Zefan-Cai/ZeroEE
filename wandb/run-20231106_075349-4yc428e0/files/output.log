11/06/2023 07:53:51 - INFO - __main__ - ***** Running training *****
11/06/2023 07:53:51 - INFO - __main__ -   Num examples = 151736
11/06/2023 07:53:51 - INFO - __main__ -   Num Epochs = 20
11/06/2023 07:53:51 - INFO - __main__ -   Instantaneous batch size per device = 16
11/06/2023 07:53:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 96
11/06/2023 07:53:51 - INFO - __main__ -   Gradient Accumulation steps = 1
11/06/2023 07:53:51 - INFO - __main__ -   Total optimization steps = 31620
  0%|                                                                                                                                                                         | 0/31620 [00:00<?, ?it/s]11/06/2023 07:53:51 - INFO - accelerate.accelerator - Loading states from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
11/06/2023 07:53:51 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
Resumed from checkpoint: /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5
[2023-11-06 07:53:51,531] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 07:53:51,544] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 07:53:51,544] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-11-06 07:53:51,555] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-11-06 07:53:51,565] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-11-06 07:53:55,554] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-11-06 07:53:55,555] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 6 ZeRO state_dicts for rank 0
11/06/2023 07:53:58 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /local1/zefan/output/Llama2_GenData_1definitions_top200/epoch_5/pytorch_model
11/06/2023 07:53:58 - INFO - accelerate.checkpointing - All model weights loaded successfully
11/06/2023 07:53:58 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
11/06/2023 07:53:58 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
11/06/2023 07:53:58 - INFO - accelerate.checkpointing - All random states loaded successfully
11/06/2023 07:53:58 - INFO - accelerate.accelerator - Loading in 0 custom states
 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:07<00:17, 1268.83it/s]

 30%|██████████████████████████████████████████████▊                                                                                                             | 9486/31620 [00:07<00:17, 1268.83it/s]11/06/2023 07:54:03 - INFO - __main__ -   Step: 9487, LR: 1.4431001684874179e-05, Loss: 0.004177939146757126
11/06/2023 07:54:07 - INFO - __main__ -   Step: 9488, LR: 1.4430349475514975e-05, Loss: 0.000276626436971128
11/06/2023 07:54:08 - INFO - __main__ - Start doing evaluation at step: 9488
  0%|                                                                                                                                                                             | 0/4 [00:00<?, ?it/s]
Traceback (most recent call last):                                                                                                                                                | 0/4 [00:00<?, ?it/s]
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 731, in convert_to_tensors
    tensor = as_tensor(value)
ValueError: expected sequence of length 2 at dim 1 (got 4)
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "./open_instruct/open_instruct/finetune_val.py", line 911, in <module>
    main()
  File "./open_instruct/open_instruct/finetune_val.py", line 828, in main
    for eval_batch in tqdm(val_dataloader):
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/tqdm/std.py", line 1182, in __iter__
    for obj in iterable:
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/data/data_collator.py", line 586, in __call__
    features = self.tokenizer.pad(
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 3074, in pad
    return BatchEncoding(batch_outputs, tensor_type=return_tensors)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 211, in __init__
    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)
  File "/local1/ponienkung/miniconda3/envs/tulu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 747, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`trigger` in this case) have excessive nesting (inputs type `list` where type `int` is expected).